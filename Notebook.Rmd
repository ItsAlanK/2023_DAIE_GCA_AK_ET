---
title: "Virtual Reality Interventions: Evaluating Efficacy in the Treatment of GAD"
author: "Alan Kinsella, Erik Trujillo"
date: "13/12/2023"
output: html_document
---

<!-- This is what a comment looks like-->
## Table of Contents

<!-- 1. [Setup](#setup)
2. [Data Loading](#data-load) -->
1. [Abstract](#abstract)
2. [Introduction](#introduction)
3. [Method](#method)
    - [Initial Inspection](#inspection)
    - [Data Cleanup](#cleanup)
4. [Results](#results)
5. [Discussion](#discussion)
6. [References](#references)

<!-- ### Setup <a name="setup"></a> -->
```{r include=FALSE}

# install.packages("tidyverse")
if(!require("knitr"))
library(knitr)

# Load the packages, loading tidyverse for readr, dplyr, magrittr, and ggplot2
if(!require("tidyverse"))
library(tidyverse)

if(!require("nortest"))
  install.packages("nortest")
library(nortest)
```


```{r include=FALSE} 
#Setting this up to define all chunks to show both code and output: 
knitr::opts_chunk$set(echo = TRUE)

```

<!-- ### Data Loading <a name="data-load"></a> -->
<!-- Loading our Datasets into R Studio -->
```{r include=FALSE} 
control_group <- read_csv("GROUP_12_2023_GCA_RESULTS_CONTROL.csv")
experimental_group <- read_csv("GROUP_12_2023_GCA_RESULTS_EXPERIMENTAL.csv")

```


## Abstract <a name="abstract"></a>
This study investigates the efficacy of Virtual Reality (VR) as a therapeutic tool and compares it to traditional Cognitive Behavioral Therapy (CBT). Through an experiment, participants were assigned to either VR therapy (experimental group) or traditional CBT (control group) and their GAD and State-Trait Anxiety Inventory (STAI) scores were assessed pre and post-treatment. Our statistical analysis focuses on comparing these scores to evaluate therapy effectiveness. 

## Introduction <a name="introduction"></a>
As of 2019, approximately 301 million people globally suffer from anxiety disorders, characterized by persistent feelings of anxiety and fear. Virtual Reality (VR) has emerged as a promising therapeutic tool, offering immersive exposure experiences for controlled treatment. Studies demonstrate VR's effectiveness in reducing symptoms of post-traumatic stress disorder and acrophobia, indicating its transformative potential in anxiety disorder treatments. Non-pharmacological therapies, notably Cognitive Behavioral Therapy, are commonly used for Generalized Anxiety Disorder (GAD), employing approaches like Imaginal Exposure Therapy and Stress Inoculation Training. Severity assessment often involves self-report mechanisms such as the State-Trait Anxiety Inventory and Generalized Anxiety Disorder 7-item scale, both scaled from 0 to 10, contributing to a nuanced understanding of anxiety disorders and guiding tailored therapeutic interventions.

This study will look at the results of an experiment comparing GAD and STAI scores of patients treated using traditional CBT (Control Group) and VR Therapy (Experimental Group) to identify the degree to which VR therapy has an effect compartive to proven therapy techniques.


## Method <a name="method"></a>
### Initial Inspection <a name="inspection"></a>

Initial inspection shows the same data types on both datasets. Patients are categorized by gender, and there are numeric scores for Generalized Anxiety Disorder (GAD) and State-Trait Anxiety Inventory (STAI). We have results both for pre-trial testing and post trial testing. 

Our preliminary analysis shows consistency in data types and formats. The summary is showing some insight on how the data is distributed, which may indicate initial differences between both treatments. There are also some outliers visible within the minimum values that might need to be looked at during our cleaning process. We need to first understand if negative values are possible in this type of results and if they could skew our results to the wrong conclusions.

```{r echo=FALSE} 
# Display the first few rows of the datasets (Removes 3rd row which just shows data types)
# Ref for how to remove data types: https://stackoverflow.com/questions/64734495/suppressing-the-column-classes-for-tibbles
```


```{r echo=FALSE, include=FALSE} 
cat(format(head(control_group))[-3L], sep = "\n") # Removed as only useful for first look
```


```{r echo=FALSE, include=FALSE} 
cat(format(head(experimental_group))[-3L], sep = "\n") # Removed as only useful for first look
```


<!-- Summary of the datasets -->
#### Summary of Control Group
```{r echo=FALSE} 
 summary(control_group)
```

#### Summary of Experimental Group
```{r echo=FALSE} 
 summary(experimental_group)
```

### Data Cleanup <a name="cleanup"></a>
```{r include=FALSE}
# Check for missing values
cntlMissingCount <- sum(is.na(control_group)) 
expMissingCount <- sum(is.na(experimental_group)) 

# Verifying data types 
cntlDataTypes <- str(control_group) 
expDataTypes <- str(experimental_group) 

```


During the data cleanup stage, we found `r cntlMissingCount` missing values in the control group and `r expMissingCount` missing values in the experimental group meaning no participants need to be removed for lack of data.We then verified the data types, ensuring that patient IDs were treated as character strings to avoid any numerical interpretation in our analyses, and that test results were appropriately handled as numeric values. This step was essential for accurate statistical computations.

#### Filtering values outside of test boundaries 
<!-- Filters each group to new dataset removing any results outside of what test results can be -->
<!-- GAD 0 - 21, STAI 20 - 80-->
```{r echo=FALSE}

# Converting PatientID numbers intro character strings to not get numerical data in the summary. 
control_group <- control_group %>% 
mutate(patientID = as.character(patientID))

control_group_cleaned <- control_group %>% filter(pretrial_GAD >= 0, pretrial_STAI >= 20, posttrial_GAD >= 0, posttrial_STAI >= 20, pretrial_GAD <= 21, pretrial_STAI <= 80, posttrial_GAD <= 21, posttrial_STAI <= 80)
```

``` {r echo=FALSE}

# Converting PatientID numbers intro character strings to not get numerical data in the summary. 
experimental_group <- experimental_group %>% 
mutate(patientID = as.character(patientID))

experimental_group_cleaned <- experimental_group %>% filter(pretrial_GAD >= 0, pretrial_STAI >= 0, posttrial_GAD >= 0, posttrial_STAI >= 0, , pretrial_GAD <= 21, pretrial_STAI <= 80, posttrial_GAD <= 21, posttrial_STAI <= 80) 
```

A key part of our cleanup involved filtering out test scores outside the boundaries for GAD (0-21) and STAI (20-80). This was necessary, as scores outside these ranges would not be considered clinically meaningful and could be attributed to typing error. After applying these filters, we reassessed the data to confirm that no outliers remained, which is clear in the summary minimum and maximum values. See [references for sources on test boundaries](#references)

Post-cleanup, our datasets present a more accurate reflection of the experiment results. Both control and experimental groups show data consistency, with no invalid values, and remained well distributed within the expected score ranges.This is a solid foundation for us to formulate our hypothesis. 

#### Summary of Control Group After Cleanup
``` {r echo=FALSE}
summary(control_group_cleaned) 
```

#### Summary of Experimental Group After Cleanup
``` {r echo=FALSE}
summary(experimental_group_cleaned) 
```

```{r include=FALSE}
count_control_cleaned <- count(control_group_cleaned)
count_experimental_cleaned <- count(experimental_group_cleaned)
```


#### Hypothesis Formulation

After our initial inspection, we compared the difference between means of pre-trial and post-trial scores for both GAD and STAI results. Our observations have led us to the following hypotheses:

- **Null Hypothesis (H0):** VR-based therapy does not have a significant difference in effectiveness from traditional CBT therapy in treating Generalized Anxiety Disorder (GAD).

- **Alternative Hypothesis (H1):** VR-based therapy is significantly more effective than traditional CBT therapy to threat Generalized Anxiety Disorder (GAD).

The validation of these hypotheses will be done through a statistical analysis of GAD and STAI scores from both the control (CBT) and experimental (VR) groups.


#### Visual Inspection for Normality

In order to determine the kind of testing we will run for our hypotheses, we will first review our datasets more in depth and determine if they are normally distributed or not.To begin, we will do a visual inspection using Box Plots, histograms, density plots and QQ plots. 

``` {r echo=FALSE}
# Adding a 'group' column to each dataset, this is so we can combine them next and we can keep differentiating them. 
control_group_cleaned$group <- 'Control'
experimental_group_cleaned$group <- 'Experimental'

# Combining the datasets, this will help us compare the data in different plots.
combined_groups <- rbind(control_group_cleaned, experimental_group_cleaned)
```


#### Visualization of GAD results for pre-trial and post-trial groups

The boxplots provide an initial visual indication of the data's distribution. In the control group, the boxplot reveals a slight asymmetry in post-trial GAD scores, suggesting potential skewness. Comparatively, the experimental group's boxplots shows a more symmetric distribution, aligning closer with normality. 

```{r echo=FALSE, comment=NA}

# Visualizing the pre-trial GAD scores by group using a boxplot
ggplot(combined_groups, aes(x = group, y = pretrial_GAD, fill = group)) +
    geom_boxplot(outlier.colour ="black", outlier.shape = 8, outlier.size = 10) +
    labs(title = "Pre-Trial GAD Scores by Group", x = "Group", y = "Pre-Trial GAD Score")

control_pretrial_GAD_mean <- mean(control_group_cleaned$pretrial_GAD)
experimental_pretrial_GAD_mean <- mean(experimental_group_cleaned$pretrial_GAD)

cat("Control Pre Trial mean GAD score: ", control_pretrial_GAD_mean)
cat("Experimental Pre Trial mean GAD score: ", experimental_pretrial_GAD_mean, sep="\n")
```


```{r echo=FALSE, comment=NA}
control_posttrial_GAD_mean <- mean(control_group_cleaned$posttrial_GAD)

# Visualizing the post-trial GAD scores by group using a boxplot
ggplot(combined_groups, aes(x = group, y = posttrial_GAD, fill = group)) +
    geom_boxplot(outlier.colour = "black", outlier.shape = 8, outlier.size = 10) +
    labs(title = "Post-Trial GAD Scores by Group", x = "Group", y = "Post-Trial GAD Score")

control_posttrial_GAD_mean <- mean(control_group_cleaned$posttrial_GAD)
experimental_posttrial_GAD_mean <- mean(experimental_group_cleaned$posttrial_GAD)


cat("Control Post Trial mean GAD score: ", control_posttrial_GAD_mean)
cat("Experimental Post Trial mean GAD score: ", experimental_posttrial_GAD_mean, sep="\n")
```

In this joint histograms and density plots we can look for the distribution curves of our data. The control group's pre-trial GAD scores exhibit a bell-shaped curve but with noticeable deviations, hinting at a non-normal distribution; the same can be said of the Experimental group's post-trial results. In contrast, the experimental group's pre-trial GAD scores display a more uniform bell shape, suggesting normality. The varying peak heights and spread of the histograms across different test scores highlight the diverse response patterns between the two groups.

```{r echo=FALSE}
# Histogram for GAD scores
ggplot(combined_groups) +
  geom_histogram(aes(x = pretrial_GAD, fill = "Pretrial"), bins = 30, alpha = 0.6) +
  geom_histogram(aes(x = posttrial_GAD, fill = "Posttrial"), bins = 30, alpha = 0.6) +
  facet_wrap(~ group) +
  labs(title = "Histogram of GAD Scores", x = "GAD Score", y = "Score") +
  scale_fill_manual(values = c("Pretrial" = "blue", "Posttrial" = "red"))
```

```{r echo=FALSE}
# Density plot for GAD scores
ggplot(combined_groups, aes(x = pretrial_GAD, fill = "Pretrial")) +
  geom_density(alpha = 0.5) +
  geom_density(aes(x = posttrial_GAD, fill = "Posttrial"), alpha = 0.5) +
  scale_fill_manual(values = c("Pretrial" = "blue", "Posttrial" = "red")) +
  labs(title = "Density Plot of GAD Scores", x = "GAD Score", y = "Density") +
  facet_wrap(~ group)
```

The QQ plots for both groups reveal a normal tendency of the central data and showcase some clear but small number of outliers. Control group's pre-trial GAD results and Experimental group's post-trial results show the most distance from the projected line of normality at both tails. 

```{r echo=FALSE}

# Set up a 2x2 layout for the plots, trying to reduce space taken by all of them. 
par(mfrow = c(2, 2))

# QQ plot for Control Group Pretrial GAD
qqnorm(control_group_cleaned$pretrial_GAD, main = "Control Group Pretrial GAD")
qqline(control_group_cleaned$pretrial_GAD, col = "red")

# QQ plot for Control Group Posttrial GAD
qqnorm(control_group_cleaned$posttrial_GAD, main = "Control Group Posttrial GAD")
qqline(control_group_cleaned$posttrial_GAD, col = "red")

# QQ plot for Experimental Group Pretrial GAD
qqnorm(experimental_group_cleaned$pretrial_GAD, main = "Experimental Group Pretrial GAD")
qqline(experimental_group_cleaned$pretrial_GAD, col = "red")

# QQ plot for Experimental Group Posttrial GAD
qqnorm(experimental_group_cleaned$posttrial_GAD, main = "Experimental Group Posttrial GAD")
qqline(experimental_group_cleaned$posttrial_GAD, col = "red")

# Reset the layout to default
par(mfrow = c(1, 1))
```



#### Visualization of STAI results for pre-trial and post-trial groups

When reviewing STAI results in boxplots, we can see a slight asymmetry in the pre-trial scores for the control group and the post-trial scores for the experimental group. The other two groups show a more symmetric distribution although it is important to not that the pre-trial experimental group contains outliers further from the IQR.  normality. 


``` {r echo=FALSE, comment=NA}
# Visualizing the pre-trial STAI scores by group using a boxplot

ggplot(combined_groups, aes(x = group, y = pretrial_STAI, fill = group)) +
    geom_boxplot(outlier.colour = "black", outlier.shape = 8, outlier.size = 10) +
    labs(title = "Pretrial STAI Scores by Group", x = "Group", y = "Pretrial STAI Score")

# Visualizing the post-trial STAI scores by group using a boxplot
ggplot(combined_groups, aes(x = group, y = posttrial_STAI, fill = group)) +
    geom_boxplot(outlier.colour = "black", outlier.shape = 8, outlier.size = 10) +
    labs(title = "Post-Trial STAI Scores by Group", x = "Group", y = "Post-Trial STAI Score")


```

``` {r echo=FALSE}

# Calling the mean of each group for future reference
control_pretrial_STAI_mean <- mean(control_group_cleaned$pretrial_STAI)
control_posttrial_STAI_mean <- mean(control_group_cleaned$posttrial_STAI)

experimental_pretrial_STAI_mean <- mean(experimental_group_cleaned$pretrial_STAI)
experimental_posttrial_STAI_mean <- mean(experimental_group_cleaned$posttrial_STAI)


cat("Control Pre Trial mean STAI score: ", control_pretrial_STAI_mean)
cat("Experimental Pre Trial mean STAI score: ", experimental_pretrial_STAI_mean, sep="\n")
```

The control group's pre-trial and post-trial STAI scores exhibit a bell-shaped curve with only slight deviations, hinting at normality. In contrast, pre-trial and post-trial results for the experimental group display a less uniform bell shape, suggesting the opposite. The varying peak heights are much more subtle than in the GAD scores. 

``` {r echo=FALSE}
# Histogram for STAI scores
ggplot(combined_groups) +
  geom_histogram(aes(x = pretrial_STAI, fill = "Pretrial"), bins = 30, alpha = 0.6) +
  geom_histogram(aes(x = posttrial_STAI, fill = "Posttrial"), bins = 30, alpha = 0.6) +
  facet_wrap(~ group) +
  labs(title = "Histogram of STAI Scores", x = "STAI Score", y = "Score") +
  scale_fill_manual(values = c("Pretrial" = "green", "Posttrial" = "orange"))
``` 

``` {r echo=FALSE}
# Density plot for STAI scores
ggplot(combined_groups, aes(x = pretrial_STAI, fill = "Pretrial")) +
  geom_density(alpha = 0.5) +
  geom_density(aes(x = posttrial_STAI, fill = "Posttrial"), alpha = 0.5) +
  scale_fill_manual(values = c("Pretrial" = "green", "Posttrial" = "orange")) +
  labs(title = "Density Plot of STAI Scores", x = "STAI Score", y = "Density") +
  facet_wrap(~ group)
```

As with the GAD scores, the STAI score's QQ plots for both testing methods reveal what seems a normal tendency of the central data and showcase some clear but small number of outliers. The only group that seems to deviate the most is the Experimental group for its post-trial results.  

```{r echo=FALSE}

# Set up a 2x2 layout for the plots, trying to reduce space taken by all of them. 
par(mfrow = c(2, 2))

# QQ plot for Control Group Pretrial STAI
qqnorm(control_group_cleaned$pretrial_STAI, main = "Control Group Pretrial STAI")
qqline(control_group_cleaned$pretrial_STAI, col = "red")

# QQ plot for Control Group Posttrial STAI
qqnorm(control_group_cleaned$posttrial_STAI, main = "Control Group Posttrial STAI")
qqline(control_group_cleaned$posttrial_STAI, col = "red")

# QQ plot for Experimental Group Pretrial STAI
qqnorm(experimental_group_cleaned$pretrial_STAI, main = "Experimental Group Pretrial STAI")
qqline(experimental_group_cleaned$pretrial_STAI, col = "red")

# QQ plot for Experimental Group Posttrial STAI
qqnorm(experimental_group_cleaned$posttrial_STAI, main = "Experimental Group Posttrial STAI")
qqline(experimental_group_cleaned$posttrial_STAI, col = "red")


par(mfrow = c(1, 1))
```

#### Testing for Normality

A combination of Anderson-Darling and Shapiro-Wilk tests were used to asses the normality of of the data. Confirming a normal distribution is needed in order to inform what tests can be run on our data in order to test our hypothesis. The combination of tests was used to ensure an accurate result. In the event of conflicting results a closer look at the data would be required to identify whether the Anderson-Darling or Shapiro-Wilk would have been more reliable given the data distributions. The results of these tests are as follows.

##### Anderson-Darling Test

``` {r echo=FALSE, comment=NA}

# Anderson-Darling Test, referenced from class example https://github.com/nmcguinness/2023_MSC_DataAnalytics_IntroToR/blob/main/Examples/9_TestingForNormality.R

control_pretrial_GAD_ad <- ad.test(control_group_cleaned$pretrial_GAD)
control_posttrial_GAD_ad <- ad.test(control_group_cleaned$posttrial_GAD)
control_pretrial_STAI_ad <- ad.test(control_group_cleaned$pretrial_STAI)
control_posttrial_STAI_ad <- ad.test(control_group_cleaned$posttrial_STAI)

print_ad_results <- function(tested_data) { # create a function with the name my_function
  if(tested_data$p.value < 0.05)
  {
    return (paste("From the output obtained we can not assume normality as the p-value of", round(tested_data$p.value, 4), "is less than 0.05 for data:", tested_data$data))
  } else #note in R we need to put the else as shown (i.e. immediately after the { bracket) and not on a new line (as we can in C, C++, C#)
  { 
    return (paste("From the output obtained we can assume normality as the p-value of", round(tested_data$p.value, 4), "is greater than 0.05 for data:", tested_data$data))
  }
}



ad_result1 <- print_ad_results(control_pretrial_GAD_ad)
ad_result2 <- print_ad_results(control_posttrial_GAD_ad)
ad_result3 <- print_ad_results(control_pretrial_STAI_ad)
ad_result4 <- print_ad_results(control_posttrial_STAI_ad)

```

- `r ad_result1`
- `r ad_result2`
- `r ad_result3`
- `r ad_result4`


##### Shapiro-Wilk Test
``` {r echo=FALSE, comment = NA}
control_pretrial_GAD_sw <- shapiro.test(control_group_cleaned$pretrial_GAD)
control_posttrial_GAD_sw <- shapiro.test(control_group_cleaned$posttrial_GAD)
control_pretrial_STAI_sw <- shapiro.test(control_group_cleaned$pretrial_STAI)
control_posttrial_STAI_sw <- shapiro.test(control_group_cleaned$posttrial_STAI)

print_sw_results <- function(tested_data) { # create a function with the name my_function
  if(tested_data$p.value < 0.05)
{
  return (paste("From the output obtained we can not assume normality as the p-value of", round(tested_data$p.value, 4), "is less than 0.05 for data:", tested_data$data))
} else
{ 
  return (paste("From the output obtained we can assume normality as the p-value of", round(tested_data$p.value, 4), "is greater than 0.05 for data:", tested_data$data))
}
}

sw_result1 <- print_sw_results(control_pretrial_GAD_sw)
sw_result2 <- print_sw_results(control_posttrial_GAD_sw)
sw_result3 <- print_sw_results(control_pretrial_STAI_sw)
sw_result4 <- print_sw_results(control_posttrial_STAI_sw)
```

- `r sw_result1`
- `r sw_result2`
- `r sw_result3`
- `r sw_result4`


From results of all Normality tests we can conclusively confirm the data to be normally distributed.

### Results <a name="results"></a>
### Hypothesis testings

Now that we have tested for normality, we can assume that all datasets are normally distributed, which allows us to proceed with parametric tests. Our focus is the change in scores from pre-trial to post-trial within each group. To analyze this, we'll use paired T-tests, comparing pre-trial and post-trial scores for each participant within the control and experimental groups. This allows us to assess the effect of each treatment type within the respective groups and establish a comparison for their effectiveness. 

```{r echo=FALSE}

# Calculate change in GAD scores
control_group_results <- control_group_cleaned$posttrial_GAD - control_group_cleaned$pretrial_GAD
experimental_group_results <- experimental_group_cleaned$posttrial_GAD - experimental_group_cleaned$pretrial_GAD

# Independent t-test for comparing changes between groups
t.test(control_group_results, experimental_group_results)

# Calculate change in STAI scores
control_group_results_STAI <- control_group_cleaned$posttrial_STAI - control_group_cleaned$pretrial_STAI
experimental_group_results_STAI <- experimental_group_cleaned$posttrial_STAI - experimental_group_cleaned$pretrial_STAI

# Independent t-test for comparing changes between groups
t.test(control_group_results_STAI, experimental_group_results_STAI)


```

Our analysis, utilizing Welch's Two Sample t-tests, revealed a statistically significant difference in treatment effectiveness between the control group (CBT) and the experimental group (VR therapy) for both GAD (Generalized Anxiety Disorder) and STAI (State-Trait Anxiety Inventory) scores.

For GAD scores, the p-value obtained was approximately 4.143e-10, which indicates an extremely low probability of observing the same difference by chance. This p-value strongly refutes the null hypothesis (H0) that VR-based therapy has no significant difference in effectiveness compared to traditional CBT therapy for GAD. The negative mean change in both groups reflects a decrease in GAD scores post-treatment, with the experimental group demonstrating a more substantial reduction.

Similarly, for STAI scores, the p-value obtained was approximately 9.28e-14, once again emphasizing a very low likelihood of obtaining these results by chance. This p-value also rejects the null hypothesis (H0) that there is no difference in effectiveness between the two treatment methods for reducing anxiety levels. The negative mean change in the experimental group indicates a reduction in anxiety levels, contrasting with the control group, where a negative value was not reached.

In summary, both extremely low p-values provide strong evidence that VR-based therapy is significantly more effective than traditional CBT therapy in reducing symptoms of Generalized Anxiety disorder.



### Discussion <a name="discussion"></a>



### References <a name="references"></a>

- [STAI Information informing min/max scores](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6945947/#:~:text=Each%20question%20is%20rated%20on,T%20and%20STAI%2DS%20subscales.)
- [GAD Information informing min/max scores](https://www.corc.uk.net/outcome-experience-measures/generalised-anxiety-disorder-assessment-gad-7)
- Normality testing conditional logic from [Class Example 9](https://github.com/nmcguinness/2023_MSC_DataAnalytics_IntroToR/blob/main/Examples/9_TestingForNormality.R)